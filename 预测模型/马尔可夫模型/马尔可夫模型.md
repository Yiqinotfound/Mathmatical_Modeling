# **马尔可夫模型**


## 1. 模型概览


### 1.1 学科分属


**基本学科归属：** 预测主题-离散模型预测


**需要背景知识：** 概率论， 矩阵运算，Viterbi算法，贝叶斯模型，最大似然，强化学习基础知识。


### 1.2 历史发展[^1]


1906年，Andrey Andreyevich Markov为了描述随机过程首次提出了马尔科夫链，并应用在俄语字符序列的计算中。在随后的半个世纪中，该概念深刻影响了数学，统计，计算机，物理学，生物学，语言学等各个领域。


大名鼎鼎的MCMC本质上是将马尔可夫链用于对蒙特卡洛方法的积分过程中，由梅特罗波利斯于1953年在洛斯阿拉莫斯国家实验室提出。那时美国洛斯阿拉莫斯是当时少数几个拥有大规模计算机的城市，梅特罗波利斯则利用这种计算优势，在蒙特卡洛方法的基础上引入马尔可夫链，用于模拟某种液体在气化之后的平衡状态。1984年Stuart和Donald Geman兄弟对吉布斯采样进行了描述，而吉布斯采样就是一种简单且广泛适用的马尔可夫链蒙特卡洛（MCMC）算法。


1957年，RICHARD BELLMAN提出了马尔可夫决策过程，这是基于马尔可夫过程理论的随机动态系统的最优决策过程，而马尔可夫过程的原始模型就是马尔可夫链。1980年，《Markov random fields and their applications》出版，详细描述了马尔可夫随机场的理论和应用，马尔可夫随机场实际上是马尔可夫过程的一个多维版本。1988年，Judea Pearl在其著作*Probabilistic reasoning in intelligent systems: networks of plausible inference*中提出了马尔可夫毯的概念。1991年，Lovejoy 研究了部分可观测马尔可夫决策过程（POMDP）。1995年D. P. Bertsekas 和 J. N. Tsitsiklis讨论了一类用于不确定条件下的控制和顺序决策的动态规划方法。 这些方法具有处理长期以来由于状态空间较大或缺乏准确模型而难以处理的问题的潜力，他们将规划所基于的环境表述为马尔可夫决策过程，这即是目前深度学习领域流行的强化学习的雏形。


1966年起，Leonard E. Baum等学者在一系列研究中提出了隐马尔可夫模型（Hidden Markov Model，HMM），它用来描述一个含有隐含未知参数的马尔可夫过程。1975年，Baker 将 HMM 用于语音识别，从那以后，HMM成为了大多数现代自动语音识别系统的基础。20世纪80年代起，HMM 也开始用于分析生物序列（DNA）。


在经济金融领域，James D. Hamilton 1989年机应用了制转换模型，其中马尔科夫链用来对高GDP增长速度时期与低GDP增长速度时期（换言之，经济扩张与紧缩）的转换进行建模。S.Brin和L.Page提出的谷歌所使用的网页排序算法（PageRank）（1998年），也是由马尔可夫链定义的。


在深度学习领域，Yoshua Bengio 等研究者于2017年提出了 GibbsNet，旨在通过匹配模型期望的联合分布和数据驱动的联合分布直接定义和学习转换算子（transition operator），然后使用转换算子训练图模型，成功将马尔科夫链与神经网络结合起来。同年，Jiaming Song, Shengjia Zhao和Stefano Ermon研究了生成对抗的训练方法来对马尔可夫链（Markov chain）的转移算子（transition operator）进行学习，目的是将其静态分布（stationary distribution）和目标数据分布相匹配。他们提出了一种新型的训练流程，以避免从静态分布中直接采样，但是仍然有能力逐渐达到目标分布。此模型可以从随机噪声开始，是无似然性的，并且能够在单步运行期间生成多个不同的样本。初步试验结果显示，当它临近其静态时，马尔可夫链可以生成高质量样本，即使是对于传统生成对抗网络相关理念中的较小结构亦是如此。


## 2. 模型介绍


### 2.1 模型概览与分类


马尔可夫模型是用于对伪随机变化系统进行建模的随机模型。它假设未来状态仅取决于当前状态，而不依赖于之前发生的事件（即马尔可夫性质，或无记忆性）。[^2]


依据实际问题的序列可观测和受控情况，马尔可夫模型具有以下常见模型。


|          | 系统状态完全可观测 | 系统状态部分可观测     |
|----------|-----------|---------------|
| **系统自主** | 马尔可夫链     | 隐马尔可夫模型       |
| **系统受控** | 马尔可夫决策过程  | 部分可观测马尔可夫决策过程 |


### 2.2 具体模型介绍


#### 2.2.1 马尔可夫链


马尔可夫链为状态空间中经过从一个状态到另一个状态的转换的随机过程，可以表示为一个链形式的有向图。假设问题具有马尔可夫性质，并设初始状态矩阵 $$P_0=[a, b, c, d]^T$$ ，观察下图，可以写出状态转移矩阵
$$
S^T = \left[
 \begin{matrix}
   0 & 0.1 & 0.4 & 0.5 \\
   0.3 & 0 & 0 & 0.7 \\
   0 & 0 & 0 & 1 \\
   0 & 0.4 & 0.6 & 0 
  \end{matrix}
  \right]
$$



![](img_0.png)



若已知状态$$P_n$$，则下一状态$$P_{n+1}=S P_n$$，可知通式$$P_n=S^n P_0$$。马尔可夫链不总是收敛的，也不一定存在稳态，最简单的例子就是下图所示的环。



![](img_1.png)



如果模型存在稳态且能够收敛，即$$\lim\limits_{n \to \infty}S^n P_0=P$$，则必有$$S P=P$$，即$$P$$为$$S$$对应特征值1的特征向量。$$P$$不必唯一，即不同初状态可以收敛于不同稳态。


#### 2.2.2 隐马尔可夫模型


隐马尔可夫模型的原理是在马尔科夫模型的基础之上，隐马尔可夫模型是关于时序的概念模型，描述了由一个隐藏的马尔可夫链随机产生不可观测的状态随机序列，再由各个状态生成一个观测而产生的观测随机序列的过程。简单来说，就是原来马尔科夫链上的信息不再可知，但由其产生的影响可知，并以此反推隐藏序列。



![](img_2.png)



简单举例解释，正好今天是疯狂星期四，假如有A，B，C三类汉堡套餐，分别可选（类别后为选择的概率，且汉堡间的转移矩阵也已知）（九珍0.5，咖啡0.5），（九珍0.3，可乐0.2，咖啡0.2，气泡水0.2，红茶0.1），（九珍0.4，咖啡0.1，气泡水0.25，红茶0.25）。小元今天吃了三种套餐，但事后不记得买了什么，只记得依次喝了可乐，九珍，咖啡。求解最可能的套餐购买顺序，即可用隐马尔科夫模型。


记初状态$$P_0$$，状态转移矩阵$$A$$，观测矩阵$$B$$。这三个参数就能确定一个隐马尔可夫模型[^3]。模型学习采用最大似然法，求得隐变量的后验分布，计算全数据的对数似然的在此后验分布下的期望的最大值。具体过程参见 [^4]。 


HMM中使用了一个重要算法Viterbi算法。该算法是一种动态规划剪枝方法，可以将暴力方法的指数复杂度降低到线性复杂度。


#### 2.2.3 马尔可夫决策过程


马尔可夫决策过程是强化学习中一个常见的概念。以十分常见的学生图为例，该模型中同样存在初状态和状态转移矩阵。



![](img_3.png)


定义马尔可夫奖励过程（Markov Reward Process，MRP），包含初状态和状态转移矩阵，另加奖励函数和奖励率。如下图，用强化学习的思想来描述，智能体处于某个状态，可以立即得到奖励$$R_x$$。



![](img_4.png)



奖励率是一个处于$$\left[0,1\right]$$的常数，作用是沿着有向图探索未来的奖励。这可以使智能体学会避免局部最优解。奖励率接近1，目光更长远，反之更考虑短期的未来。


包含决策的马尔可夫奖励过程就是马尔可夫决策过程。在奖励过程的基础上得到决策，实际上就是一个追求最大价值的简单优化求解过程。公式推导可参考[^5]。


另有部分观测马尔可夫决策过程，与普通决策过程关系类似于MC和HMM，但数学上更加复杂。


## 3. 模型介绍


### 3.1 常见应用场景


上文背景介绍中，已经提到了不少应用场景。这里选择一些介绍。


#### 3.1.1 PageRank


放在有向图中，这一算法十分容易理解。假设用户随机出现在互联网上，开始随意点击。每个网站具有指向其他网站的链接，链接位置，与用户点击概率相关。一段时间后，用户在各个位置的可能性趋于稳定。这实际上就是一个简单的马尔可夫链。事实上，上文中马尔可夫链的图就是仿照机器学习课程PageRank的PPT制作的。实际应用时，由于不断有新用户进入互联网，以及众所周知有其他因素影响网站排名，实际PageRank模型更为复杂。


#### 3.1.2 中文分词


中文分词，就是给一个汉语句子作为输入，以“BEMS”组成的序列串作为输出，然后再进行切词，进而得到输入句子的划分。其中，B代表该字是词语中的起始字，M代表是词语中的中间字，E代表是词语中的结束字，S则代表是单字成词。例如：今天是疯狂星期四。分为BE/S/BE/BME。
将HMM应用于中文分词，涉及五个要素：观测序列，即原文；状态序列，即输出；初状态，即首字为B还是S；状态转移矩阵，即对一段文本而言，前字状态转移到后字各个状态的概率矩阵；观测矩阵，即每个字对应各个状态的概率。
使用以上五个元素代入HMM，得到输出。将输出变为英文，这一问题就是翻译问题，求解方法同理。


### 3.2 例题简析


#### 3.2.1 淋雨问题


某人有 2 把伞，并在办公室和家之间往返．如果某天他在家中(办公室时)下雨而且家中(办公室)有伞他就带一把伞去上班(回家)，不下雨时他从不带伞．如果每天与以往独立地早上(晚上)下雨的概率为0.7，试求他被雨淋湿的机会。


该问题显然可用马尔可夫链解决。转移矩阵
$$
S = \left[ \begin{matrix}   0.200 & 0.4667 & 0.3333 \\   0.538 & 0.1538 & 0.3077 \\   0.363 & 0.4545 & 0.1818    \end{matrix}  \right]
$$
注意因为地点不同，行0，1，2对应列2，1，0 。使用数学计算求解，内部代码实现在第四部分给出。


```python
model = DTMC(3, state_names=['0umbrella', '1umbrella', '2umbrellas'])
model.fit([[0, 0, 1], [0, 0.3, 0.7], [0.3, 0.7, 0]])
res = model.predict(0)
cal_pro = res * 0.7
print('calculation prediction:', cal_pro)
# output: calculation prediction: 0.09135361380812396
```


使用以下代码进行模拟。


```python
rain = [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]
total = 1000000  # how many times the man travel btw home and office
wet = 0
pos = 0
umb = [1, 1]  # you can try [0,2] or [2,0]
for _ in range(total):
    shuffle(rain)
    is_rain = rain[0]
    if is_rain:
        if umb[pos] == 0:
            wet += 1
        else:
            umb[pos] -= 1
            umb[1 - pos] += 1
    pos = 1 - pos
sim_pro = wet / total
print('simulation prediction:', sim_pro)
# output: simulation prediction: 0.091577
```


可见计算结果和模拟结果接近。


#### 3.2.2 农业收成


考虑某地区农业收成变化的三个状态，即“丰收”、“平收”和“欠收”。记E1为“丰收”状态，E2为“平收”状态，E3为“欠收”状态。下表给出了该地区1950—1989年期间农业收成的情况以及状态变化：


<div class="table-box"><table align="center" border="1" cellspacing="0"><tbody><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">年份</p> </td><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">1950</p> </td><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">1951</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">1952</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">1953</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">1954</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">1955</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">1956</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">1957</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">1958</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">1959</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">序号</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">1</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">2</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">3</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">4</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">5</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">6</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">7</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">8</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">9</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">10</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">状态</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">年份</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">1960</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">1961</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1962</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1963</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1964</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1965</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1966</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1967</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1968</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1969</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">序号</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">11</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">12</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">13</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">14</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">15</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">16</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">17</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">18</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">19</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">20</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">状态</p> </td><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">年份</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">1970</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">1971</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1972</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1973</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1974</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1975</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1976</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1977</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1978</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1979</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">序号</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">21</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">22</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">23</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">24</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">25</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">26</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">27</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">28</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">29</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">30</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">状态</p> </td><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">年份</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">1980</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">1981</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1982</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1983</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1984</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1985</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1986</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1987</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1988</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">1989</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">序号</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">31</p> </td><td style="width:38.7pt;"> <p style="margin-left:0cm;">32</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">33</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">34</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">35</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">36</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">37</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">38</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">39</p> </td><td style="width:38.75pt;"> <p style="margin-left:0cm;">40</p> </td></tr><tr><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">状态</p> </td><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.7pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E3</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E1</p> </td><td style="vertical-align:top;width:38.75pt;"> <p style="margin-left:0cm;">E2</p> </td></tr></tbody></table></div>


利用pandas统计分析上表可知，在15个从E1出发的状态转移中，有3个转移到E1，有7个转移到E2，有5个转移到E3。以此类推，写出转移矩阵。


$$
S^T = \left[ \begin{matrix}   0 & 0 & 1 \\   0 & 0.3 & 0.7 \\   0.3 & 0.7 & 0    \end{matrix}  \right]
$$


代入计算即可。


## 4.软件/程序介绍


### 4.1 模拟介绍


#### 4.1.1 马尔可夫链python实现


因为普通马尔可夫链原理十分简单，在求解淋雨问题时实现了一个使用矩阵运算的马尔可夫求解器，代码及用例如下：


```python
# ~/anaconda3/env/yourEnvName python3.9
# _*_ coding:utf-8 _*_
#
# @Version : 1.0
# @Time    : 2022.8.7
# @Author  : loping151
# @File    : DTMC.py
#
# Markov Chain


from numpy import zeros, sum, array, ones




class DTMC:
    def __init__(self, size, state_names=None, init_state=None, eps=0.001, max_iter=1e5):
        if state_names is not None:
            self.state_names = state_names
        else:
            self.state_names = []
            for _ in range(size):
                self.state_names.append('state_' + str(_))
        self.size = size
        if init_state is not None:
            self.p_i = array(init_state)
        else:
            self.p_i = ones((1, self.size)) / size
        self.trans = zeros((self.size, self.size))
        self.max_iter = max_iter
        self.eps = eps
        self.result = None


    def reset_state(self, s):
        self.p_i = array(s).reshape((1, self.size))


    def fit(self, trans):
        trans = array(trans)
        res = self.p_i.copy()
        for _ in range(int(self.max_iter)):
            print('\riter', _, end='')
            rec = res.copy()
            res = res.dot(trans)
            if sum(abs(res - rec)) < self.eps:
                print('\rDTMC: Converge after', _, 'iteration(s).')
                break
            if _ == self.max_iter - 1:
                if self.eps > 0:
                    print('\rWarning: Did not converge! Epsilon too small or max_iter not enough. Final change:', sum(abs(res - rec)))
                else:
                    print('\rYou\'ve disabled Epsilon. Final change:', sum(abs(res - rec)))
        self.result = res


    def predict(self, index=None):
        if self.result is None:
            print('Fit the model first.')
            return
        if index is not None:
            if index >= self.size:
                raise IndexError
            print('\rDTMC: predict', self.state_names[index], 100 * self.result[0, index], '%')
            return self.result[0, index]
        else:
            print('\rDTMC:\n', '\b' + self.state_names[0], 100 * self.result[0, 0], '%')
            for _ in range(1, self.size):
                print(self.state_names[_], 100 * self.result[0, _], '%')
            return self.result
```


```python
# 该函数包含了所有合法使用方法
def sampleDTMC():
    mc = DTMC(4)


    mc.predict()  # Will give warning
    print('\n')


    trans = [[0, 0.1, 0.4, 0.5], [0.3, 0, 0, 0.7], [0, 0, 0, 1], [0, 0.4, 0.6, 0]]
    mc.fit(trans)
    mc.predict()
    print('\n')


    mc.reset_state([0.1, 0.2, 0.3, 0.4])  # or define as: mc = DTMC(4, init_state=[0.1, 0.2, 0.3, 0.4])
    mc.fit(trans)
    mc.predict()
    print('\n')


    mc.eps = 1e-10 # or define as: mc = DTMC(4, init_state=[0.1, 0.2, 0.3, 0.4], eps=1e-10)
    mc.fit(trans)
    mc.predict()
    print('\n')


    mc.state_names = ['sunny', 'rainy', 'foggy', 'cloudy']
    # or define as: mc = DTMC(..., state_names=['sunny', 'rainy', 'foggy', 'cloudy'])
    mc.predict(2)
    print('\n')


    mc.eps = -1  # not allow break
    # or define as: mc = DTMC(..., eps=-1)
    mc.fit(trans)
    mc.predict()
    print('\n')


    mc.eps = 0.001
    mc.max_iter = 10
    # or define as: mc = DTMC(..., max_iter=10)
    mc.fit(trans)
    mc.predict()
    print('\n')
```


#### 4.1.2 HMM使用


python有hmmlearn工具包[^6]。查阅官方文档[^7]可以快速上手。可以通过pip安装，使用官方样例（附件中有）分析来自美国地质局的地震数据。做图如下。



![](img_5.png)![](img_6.png)<![](img_7.png)



matlab中有类似工具包hmm toolbox可以简单调用。


机器学习相关的工具中，往往也含有马尔可夫相关模型。


### 4.2 R语言HMM实例


使用R包depmixS4可以调用HMM，然笔者暂未用明白。


## 修改记录


- 2022-08-12，杨伟程校对语法
- 2022-08-07，王凯灵、刘发中、夏泰熙完成写作
- 2021-08-10，郑鸿晓更新模板
- 2021-08-04，张嘉乐建立模板


[^1]:  [马尔可夫链 | 机器之心 (jiqizhixin.com)](https://www.jiqizhixin.com/graph/technologies/fdebe132-cd51-43ba-8bda-a42abc478cbb)
[^2]: [Markov model - Wikipedia](https://en.wikipedia.org/wiki/Markov_model#Introduction)
[^3]: 周志华 机器学习 清华大学出版社 2016
[^4]: https://jonathan-hui.medium.com/machine-learning-hidden-markov-model-hmm-31660d217a61
[^5]: [马尔可夫决策过程 (Markov Decision Process) - Leo Van | 范叶亮](https://leovan.me/cn/2020/05/markov-decision-process/#fn:1)
[^6]: [hmmlearn/hmmlearn: Hidden Markov Models in Python, with scikit-learn like API (github.com)](https://github.com/hmmlearn/hmmlearn)
[^7]: [hmmlearn — hmmlearn 0.2.7.post13+g6d3900d documentation](https://hmmlearn.readthedocs.io/en/latest/index.html)



